{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando Modelos\n",
    "Neste notebook vamos mostrar como fazer uso de um modelo, mas antes disso vamos primeiro carregar o nosso conjunto de dados e ajustar os tipos científicos deste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Queryverse\n",
    "using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sepallength</th><th>sepalwidth</th><th>petallength</th><th>petalwidth</th><th>variety</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>3 rows × 5 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Setosa</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& sepallength & sepalwidth & petallength & petalwidth & variety\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & Setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & Setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & Setosa \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×5 DataFrame\n",
       "│ Row │ sepallength │ sepalwidth │ petallength │ petalwidth │ variety │\n",
       "│     │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mString\u001b[39m  │\n",
       "├─────┼─────────────┼────────────┼─────────────┼────────────┼─────────┤\n",
       "│ 1   │ 5.1         │ 3.5        │ 1.4         │ 0.2        │ Setosa  │\n",
       "│ 2   │ 4.9         │ 3.0        │ 1.4         │ 0.2        │ Setosa  │\n",
       "│ 3   │ 4.7         │ 3.2        │ 1.3         │ 0.2        │ Setosa  │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = Queryverse.load(\"iris.csv\") |> DataFrame\n",
    "first(dados, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m─────────────\u001b[0m┬\u001b[0m───────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names     \u001b[0m│\u001b[0m\u001b[22m _.types                   \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m─────────────\u001b[0m┼\u001b[0m───────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m sepallength \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m sepalwidth  \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petallength \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petalwidth  \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m variety     \u001b[0m│\u001b[0m CategoricalString{UInt32} \u001b[0m│\u001b[0m Multiclass{3} \u001b[0m│\u001b[0m\n",
       "└\u001b[0m─────────────\u001b[0m┴\u001b[0m───────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 150\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(dados, autotype(dados))\n",
    "schema(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o nosso conjunto está com os tipos adequados, vamos para a escolha do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostStumpClassifier     DecisionTree\n",
      "BayesianLDA                 MultivariateStats\n",
      "BayesianSubspaceLDA         MultivariateStats\n",
      "ConstantClassifier          MLJModels\n",
      "DecisionTreeClassifier      DecisionTree\n",
      "EvoTreeClassifier           EvoTrees\n",
      "GaussianNBClassifier        NaiveBayes\n",
      "KNNClassifier               NearestNeighbors\n",
      "LDA                         MultivariateStats\n",
      "LinearBinaryClassifier      GLM\n",
      "LogisticClassifier          MLJLinearModels\n",
      "MultinomialClassifier       MLJLinearModels\n",
      "RandomForestClassifier      DecisionTree\n",
      "SubspaceLDA                 MultivariateStats\n"
     ]
    }
   ],
   "source": [
    "y, x = unpack(dados, ==(:variety), colnames -> true)\n",
    "for m in models(matching(x,y))\n",
    "    if m.prediction_type == :probabilistic &&\n",
    "        m.is_pure_julia == true\n",
    "        println(rpad(m.name, 28), m.package_name)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos então utilizar o __DecisionTreeClassifier__ do pacote __DecisionTree__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    post_prune = false,\n",
       "    merge_purity_threshold = 1.0,\n",
       "    pdf_smoothing = 0.0,\n",
       "    display_depth = 5)\u001b[34m @ 1…28\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = @load DecisionTreeClassifier pkg=\"DecisionTree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já temos o nosso modelo escolhido e temos acesso aos seus parâmetros. O que faremos agora é criar uma machine. A __machine__ é uma estrutura que encapsula tanto o modelo quanto os dados e pode conter informações do modelo treinado, ela não faz o ajuste do modelo por si só. Entretanto, ela verifica se os tipos científicos são compatíveis com o modelo e avisa caso não sejam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 1…97\u001b[39m\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arvore = machine(dtc, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __machine__ é utilizada para modelos supervisionados e não supervisionados, faremos exemplo de uso desta para os dois casos.\n",
    "\n",
    "### Modelo supervisionado\n",
    "\n",
    "Já temos carregado um modelo do tipo supervisionado, vamos começar fazendo uma divisão dos nossos dados em dados de treino e dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, teste = partition(eachindex(y), 0.7, shuffle = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ajustar os parâmetros do nosso modelo com base nos nossos dados de treino (informaremos as linhas), para isso vamos usara função __fit!__ usando a nossa __machine__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{DecisionTreeClassifier} @ 1…97\u001b[39m.\n",
      "└ @ MLJBase /home/phelipe/.julia/packages/MLJBase/uJ1jK/src/machines.jl:182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{DecisionTreeClassifier} @ 1…97\u001b[39m\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(arvore, rows=treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função __fit!__ modificou os parâmetros do nosso modelo, podemos inspecionar os resultados com o uso da função __fitted_params__ e nossa __machine__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tree = Decision Tree\n",
       "Leaves: 7\n",
       "Depth:  4,\n",
       " encoding = Dict{CategoricalString{UInt32},UInt32}(\"Versicolor\" => 0x00000002,\"Setosa\" => 0x00000001,\"Virginica\" => 0x00000003),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(arvore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O retorno da função __fitted_params__ varia de modelo para modelo, normalmente ele retorna uma tupla onde o primeiro elemento são os parâmetros ajustados do modelo e o segundo apresenta a forma como as classes foram nomeadas.\n",
    "\n",
    "É possível agora utilizar a __machine__ para fazer predições com a função __predict__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred[1] = UnivariateFinite(Setosa=>0.0, Versicolor=>0.0, Virginica=>1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UnivariateFinite(Setosa=>0.0, Versicolor=>0.0, Virginica=>1.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(arvore, rows = teste)\n",
    "@show y_pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que a saída é a probabilidade do elemento pertencer a cada uma das classes. Podemos pegar a classe com a maior probabilidade usando a função __mode__ ou já aplicando na predição com __predict_mode__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalString{UInt32} \"Virginica\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(y_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_mode[1] = \"Virginica\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoricalString{UInt32} \"Virginica\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mode = predict_mode(arvore, rows = teste)\n",
    "@show y_pred_mode[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora medir a performance do nosso classificador, a biblioteca MLJ oferece algumas medidas, algumas destas são:\n",
    "  - area_under_curve;\n",
    "  - accuracy;\n",
    "  - balanced_accuracy;\n",
    "  - BrierScore;\n",
    "  - cross_entropy;\n",
    "  - FScore;\n",
    "  - false_discovery_rate;\n",
    "  - false_negative;\n",
    "  - false_negative_rate;\n",
    "  - false_positive;\n",
    "  - false_positive_rate;\n",
    "  - l1;\n",
    "  - l2;\n",
    "  - mae;\n",
    "  - matthews_correlation;\n",
    "  - misclassification_rate;\n",
    "  - negative_predictive_value;\n",
    "  - positive_predictive_value;\n",
    "  - rms;\n",
    "  - rmsl;\n",
    "  - rmslp1;\n",
    "  - rmsp;\n",
    "  - true_negative;\n",
    "  - true_negative_rate;\n",
    "  - true_positive;\n",
    "  - true_positive_rate;\n",
    "  \n",
    "Mais detalhes sobre as medidasde deempenho podem ser obtida na [documentação.](https://alan-turing-institute.github.io/MLJ.jl/stable/performance_measures/)\n",
    "\n",
    "Podemos fazer uso da função __measures__ para ver todas as funções disponívies.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_under_curve             score\n",
      "accuracy                     score\n",
      "balanced_accuracy            score\n",
      "cross_entropy                loss\n",
      "FScore                       score\n",
      "false_discovery_rate         loss\n",
      "false_negative               loss\n",
      "false_negative_rate          loss\n",
      "false_positive               loss\n",
      "false_positive_rate          loss\n",
      "l1                           loss\n",
      "l2                           loss\n",
      "mae                          loss\n",
      "matthews_correlation         score\n",
      "misclassification_rate       loss\n",
      "negative_predictive_value    score\n",
      "positive_predictive_value    score\n",
      "rms                          loss\n",
      "rmsl                         loss\n",
      "rmslp1                       loss\n",
      "rmsp                         loss\n",
      "true_negative                score\n",
      "true_negative_rate           score\n",
      "true_positive                score\n",
      "true_positive_rate           score\n",
      "BrierScore{UnivariateFinite} score\n",
      "DWDMarginLoss()              loss\n",
      "ExpLoss()                    loss\n",
      "L1HingeLoss()                loss\n",
      "L2HingeLoss()                loss\n",
      "L2MarginLoss()               loss\n",
      "LogitMarginLoss()            loss\n",
      "ModifiedHuberLoss()          loss\n",
      "PerceptronLoss()             loss\n",
      "ScaledMarginLoss()           loss\n",
      "SigmoidLoss()                loss\n",
      "SmoothedL1HingeLoss()        loss\n",
      "ZeroOneLoss()                loss\n",
      "HuberLoss()                  loss\n",
      "L1EpsilonInsLoss()           loss\n",
      "L2EpsilonInsLoss()           loss\n",
      "LPDistLoss()                 loss\n",
      "LogitDistLoss()              loss\n",
      "PeriodicLoss()               loss\n",
      "QuantileLoss()               loss\n",
      "ScaledDistanceLoss()         loss\n",
      "confusion_matrix             other\n"
     ]
    }
   ],
   "source": [
    "for m in measures()\n",
    "    println(rpad(m.name, 29), m.orientation)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos separar somente as funções utilizadas para verificar o score de um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_under_curve             \n",
      "accuracy                     \n",
      "balanced_accuracy            \n",
      "FScore                       \n",
      "matthews_correlation         \n",
      "negative_predictive_value    \n",
      "positive_predictive_value    \n",
      "true_negative                \n",
      "true_negative_rate           \n",
      "true_positive                \n",
      "true_positive_rate           \n",
      "BrierScore{UnivariateFinite} \n"
     ]
    }
   ],
   "source": [
    "for m in measures()\n",
    "    if m.orientation == :score\n",
    "        println(rpad(m.name, 29))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então utilizar algumas destas para verificar o desempenho do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_pred_mode, y[teste])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576923076923077"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy(y_pred_mode, y[teste])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também faze a matriz de confusão do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using order: [\"Setosa\", \"Versicolor\", \"Virginica\"].\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase /home/phelipe/.julia/packages/MLJBase/uJ1jK/src/measures/confusion_matrix.jl:87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌─────────────────────────────────────────┐\n",
       "              │              Ground Truth               │\n",
       "┌─────────────┼─────────────┬─────────────┬─────────────┤\n",
       "│  Predicted  │   Setosa    │  Versicol…  │  Virginica  │\n",
       "├─────────────┼─────────────┼─────────────┼─────────────┤\n",
       "│   Setosa    │     12      │      0      │      0      │\n",
       "├─────────────┼─────────────┼─────────────┼─────────────┤\n",
       "│  Versicol…  │      0      │     12      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┼─────────────┤\n",
       "│  Virginica  │      0      │      1      │     19      │\n",
       "└─────────────┴─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_mode, y[teste])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo não supervisionado\n",
    "\n",
    "Agora faremos o uso de um modelo não supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{UnivariateStandardizer} @ 1…95\u001b[39m\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = [1, 2, 3, 4]\n",
    "stand_model = UnivariateStandardizer()\n",
    "stand = machine(stand_model, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{UnivariateStandardizer} @ 1…95\u001b[39m.\n",
      "└ @ MLJBase /home/phelipe/.julia/packages/MLJBase/uJ1jK/src/machines.jl:182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{UnivariateStandardizer} @ 1…95\u001b[39m\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(stand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos não supervisionados definem um método __transform__, e podem implementar opcionalmente um método __inverse_transform__ . Assim como no caso supervisionado, aqui também fizemos o uso de uma __machine__ para guardar o nosso modelo e nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -1.161895003862225\n",
       " -0.3872983346207417\n",
       "  0.3872983346207417\n",
       "  1.161895003862225"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = transform(stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round.(w, digits = 2) = [-1.16, -0.39, 0.39, 1.16]\n",
      "mean(w) = 0.0\n",
      "std(w) = 1.0\n"
     ]
    }
   ],
   "source": [
    "@show round.(w, digits=2)\n",
    "@show mean(w)\n",
    "@show std(w);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso nosso modelo tem uma transformação inversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv = inverse_transform(stand, w)\n",
    "sum(abs.(vv .- v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia IA 1.4.0",
   "language": "julia",
   "name": "julia-ia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
