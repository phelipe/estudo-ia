{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Aqui começaremos a fazer uso da função evaluate para fazer uma análise do desempenho de um modelo para diferentes medidas de desempenho, isso pode ajudar na escolha inicial de qual modelo utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Queryverse\n",
    "using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeRegressor(\n",
       "    lambda = 1.0)\u001b[34m @ 1…50\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load RidgeRegressor pkg=MultivariateStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeRegressor(\n",
       "    lambda = 1.0)\u001b[34m @ 1…82\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RidgeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{RidgeRegressor} @ 1…57\u001b[39m\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (a=rand(12), b=rand(12), c=rand(12));\n",
    "y = X.a + 2X.b + 0.05*rand(12);\n",
    "mach = machine(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos por exemplo analisar o desempenho desse modelo para diferentes medidas  de desempenho que sejam de interesse, aqui usarei o evaluate para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 6 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m mae       \u001b[0m│\u001b[0m 0.249         \u001b[0m│\u001b[0m [0.197, 0.132, 0.0656, 0.619, 0.374, 0.106]   \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rmslp1    \u001b[0m│\u001b[0m 0.166         \u001b[0m│\u001b[0m [0.0912, 0.0443, 0.0289, 0.363, 0.146, 0.045] \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rms       \u001b[0m│\u001b[0m 0.416         \u001b[0m│\u001b[0m [0.239, 0.134, 0.0862, 0.812, 0.527, 0.147]   \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [missing, missing, missing]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(mach, measure=[mae, rmslp1 , rms])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso modificar o método de reamostrar os dados entre teste e treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m───────────────────────────────────────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold                                    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m───────────────────────────────────────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m mae       \u001b[0m│\u001b[0m 0.254         \u001b[0m│\u001b[0m [0.196, 0.134, 0.0764, 0.605, 0.0503, 0.464]  \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rmslp1    \u001b[0m│\u001b[0m 0.165         \u001b[0m│\u001b[0m [0.093, 0.0477, 0.0252, 0.358, 0.0225, 0.154] \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rms       \u001b[0m│\u001b[0m 0.415         \u001b[0m│\u001b[0m [0.244, 0.155, 0.0764, 0.798, 0.0696, 0.549]  \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m───────────────────────────────────────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [missing, missing, missing]\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(mach, resampling = CV( shuffle = true),\n",
    "    measure=[mae, rmslp1 , rms], verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m───────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.measure \u001b[0m│\u001b[0m\u001b[22m _.measurement \u001b[0m│\u001b[0m\u001b[22m _.per_fold \u001b[0m│\u001b[0m\n",
       "├\u001b[0m───────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m mae       \u001b[0m│\u001b[0m 0.0986        \u001b[0m│\u001b[0m [0.0986]   \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rmslp1    \u001b[0m│\u001b[0m 0.0391        \u001b[0m│\u001b[0m [0.0391]   \u001b[0m│\u001b[0m\n",
       "│\u001b[0m rms       \u001b[0m│\u001b[0m 0.116         \u001b[0m│\u001b[0m [0.116]    \u001b[0m│\u001b[0m\n",
       "└\u001b[0m───────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n",
       "_.per_observation = [missing, missing, missing]\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate!(mach, resampling = Holdout( shuffle = true),\n",
    "    measure = [mae, rmslp1 , rms], verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas das formas de fazer a reamostragem são:\n",
    "  - Holdout (Estratégia de reamostragem de holdout)\n",
    "  - CV (Estratégia de reamostragem de validação cruzada)\n",
    "  - StratifiedCV (Estratégia estratificada de reamostragem de validação cruzada\n",
    ")\n",
    "\n",
    "\n",
    "Mais detalhes em: https://alan-turing-institute.github.io/MLJ.jl/stable/evaluating_model_performance/#Custom-resampling-strategies-1\n",
    "\n",
    "\n",
    "A grande utilidade disso é fazer evaluate de diversos modelos diferentes e comparar as medidas para escolher qual seria um bom para ser aprofundado para melhorar o desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia IA 1.4.0",
   "language": "julia",
   "name": "julia-ia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
