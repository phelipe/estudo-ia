{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolhendo Modelos\n",
    "\n",
    "Agora que já vimos o básico sobre a preparação dos dados, vamos ver como escolher um modelo para a classficação ou predição do nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Queryverse\n",
    "using MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sepallength</th><th>sepalwidth</th><th>petallength</th><th>petalwidth</th><th>variety</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>String</th></tr></thead><tbody><p>3 rows × 5 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>Setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>Setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>Setosa</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& sepallength & sepalwidth & petallength & petalwidth & variety\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & Setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & Setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & Setosa \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×5 DataFrame\n",
       "│ Row │ sepallength │ sepalwidth │ petallength │ petalwidth │ variety │\n",
       "│     │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mString\u001b[39m  │\n",
       "├─────┼─────────────┼────────────┼─────────────┼────────────┼─────────┤\n",
       "│ 1   │ 5.1         │ 3.5        │ 1.4         │ 0.2        │ Setosa  │\n",
       "│ 2   │ 4.9         │ 3.0        │ 1.4         │ 0.2        │ Setosa  │\n",
       "│ 3   │ 4.7         │ 3.2        │ 1.3         │ 0.2        │ Setosa  │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = Queryverse.load(\"iris.csv\") |> DataFrame\n",
    "first(dados, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificaremos os tipos científicos que serão utilizados pelo nosso conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m─────────────\u001b[0m┬\u001b[0m─────────\u001b[0m┬\u001b[0m────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names     \u001b[0m│\u001b[0m\u001b[22m _.types \u001b[0m│\u001b[0m\u001b[22m _.scitypes \u001b[0m│\u001b[0m\n",
       "├\u001b[0m─────────────\u001b[0m┼\u001b[0m─────────\u001b[0m┼\u001b[0m────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m sepallength \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m sepalwidth  \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petallength \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petalwidth  \u001b[0m│\u001b[0m Float64 \u001b[0m│\u001b[0m Continuous \u001b[0m│\u001b[0m\n",
       "│\u001b[0m variety     \u001b[0m│\u001b[0m String  \u001b[0m│\u001b[0m Textual    \u001b[0m│\u001b[0m\n",
       "└\u001b[0m─────────────\u001b[0m┴\u001b[0m─────────\u001b[0m┴\u001b[0m────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 150\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como no notebook anterior mudaremos o tipo da nossa classe __variety__ para um tipo mais adequado para classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌\u001b[0m─────────────\u001b[0m┬\u001b[0m───────────────────────────\u001b[0m┬\u001b[0m───────────────\u001b[0m┐\u001b[0m\n",
       "│\u001b[0m\u001b[22m _.names     \u001b[0m│\u001b[0m\u001b[22m _.types                   \u001b[0m│\u001b[0m\u001b[22m _.scitypes    \u001b[0m│\u001b[0m\n",
       "├\u001b[0m─────────────\u001b[0m┼\u001b[0m───────────────────────────\u001b[0m┼\u001b[0m───────────────\u001b[0m┤\u001b[0m\n",
       "│\u001b[0m sepallength \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m sepalwidth  \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petallength \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m petalwidth  \u001b[0m│\u001b[0m Float64                   \u001b[0m│\u001b[0m Continuous    \u001b[0m│\u001b[0m\n",
       "│\u001b[0m variety     \u001b[0m│\u001b[0m CategoricalString{UInt32} \u001b[0m│\u001b[0m Multiclass{3} \u001b[0m│\u001b[0m\n",
       "└\u001b[0m─────────────\u001b[0m┴\u001b[0m───────────────────────────\u001b[0m┴\u001b[0m───────────────\u001b[0m┘\u001b[0m\n",
       "_.nrows = 150\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerce!(dados, autotype(dados))\n",
    "schema(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que nosso dado está com os tipos científicos adequados vamos separar em dados de entrada e saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = unpack(dados, ==(:variety), colname -> true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pacote MLJ, um modelo (_**model**_) é uma struct que guarda os hyperparâmetros dos algoritmos de aprendizagem utilizados pelo pacote. Com o conjunto de dados (x, y) e o uso das funções __model__ e __matching__ do pacote MLJ, podemos verificar quais modelos são adequados para os tipos científicos do nosso conjunto de dados.\n",
    "\n",
    "**Obs: para usar um modelo é necessário ter instalado o pacote do qual ele depende.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos = models(matching(x, y));\n",
    "length(modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um total de 41 modelos disponíveis para uso com o nosso conjunto de dados. Vamos verificar melhor as propriedades do tipo modelo, para isto vamos pegar um dos modelos retornado na nossa pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[35mBayesian Linear Discriminant Analysis.\u001b[39m\n",
       "\u001b[35m→ based on [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl).\u001b[39m\n",
       "\u001b[35m→ do `@load BayesianLDA pkg=\"ScikitLearn\"` to use the model.\u001b[39m\n",
       "\u001b[35m→ do `?BayesianLDA` for documentation.\u001b[39m\n",
       "(name = \"BayesianLDA\",\n",
       " package_name = \"ScikitLearn\",\n",
       " is_supervised = true,\n",
       " docstring = \"Bayesian Linear Discriminant Analysis.\\n→ based on [ScikitLearn](https://github.com/cstjean/ScikitLearn.jl).\\n→ do `@load BayesianLDA pkg=\\\"ScikitLearn\\\"` to use the model.\\n→ do `?BayesianLDA` for documentation.\",\n",
       " hyperparameter_ranges = (nothing, nothing, nothing, nothing, nothing, nothing),\n",
       " hyperparameter_types = (\"String\", \"Union{Nothing, Float64, String}\", \"Union{Nothing, AbstractArray{T,1} where T}\", \"Union{Nothing, Int64}\", \"Bool\", \"Float64\"),\n",
       " hyperparameters = (:solver, :shrinkage, :priors, :n_components, :store_covariance, :tol),\n",
       " implemented_methods = [:predict, :clean!, :fit, :fitted_params],\n",
       " is_pure_julia = false,\n",
       " is_wrapper = false,\n",
       " load_path = \"MLJModels.ScikitLearn_.BayesianLDA\",\n",
       " package_license = \"BSD\",\n",
       " package_url = \"https://github.com/cstjean/ScikitLearn.jl\",\n",
       " package_uuid = \"3646fa90-6ef7-5e7e-9f22-8aca16db6324\",\n",
       " prediction_type = :probabilistic,\n",
       " supports_online = false,\n",
       " supports_weights = false,\n",
       " input_scitype = Table{_s23} where _s23<:(AbstractArray{_s25,1} where _s25<:Continuous),\n",
       " target_scitype = AbstractArray{_s656,1} where _s656<:Finite,\n",
       " output_scitype = Unknown,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos muitas informações mas aqui queremos destacar as que consideramos mais importantes inicialmente: \n",
    "  - **name** -> nome do modelo dentro do pacote MLJ;\n",
    "  - **package_name** -> nome do pacote que deve ser instalado para que o modelo possa ser utilizado;\n",
    "  - **is_supervised** -> informa se o modelo é do tipo supervisionado;\n",
    "  - **prediction_type** -> informa o tipo de predição, alguns dos tipo disponíveis são:\n",
    "    - determinístico (deterministic);\n",
    "    - probabilístico (probabilistic);\n",
    "    - desconhecido (unknows).\n",
    "    \n",
    "Com base no seu conjunto de dados voê deve determinar qual abordagem é melhor para você. Vamos supor que você quer que os seus dados sejam usados em uma abordagem probabilística, para isso vamos fazer o uso novamente das funções __models__ e __matching__ e depois separar somente as abordagens probabilísticas.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier          (ScikitLearn)\n",
      "AdaBoostStumpClassifier     (DecisionTree)\n",
      "BaggingClassifier           (ScikitLearn)\n",
      "BayesianLDA                 (MultivariateStats)\n",
      "BayesianLDA                 (ScikitLearn)\n",
      "BayesianQDA                 (ScikitLearn)\n",
      "BayesianSubspaceLDA         (MultivariateStats)\n",
      "ConstantClassifier          (MLJModels)\n",
      "DecisionTreeClassifier      (DecisionTree)\n",
      "DummyClassifier             (ScikitLearn)\n",
      "EvoTreeClassifier           (EvoTrees)\n",
      "ExtraTreesClassifier        (ScikitLearn)\n",
      "GaussianNBClassifier        (NaiveBayes)\n",
      "GaussianNBClassifier        (ScikitLearn)\n",
      "GaussianProcessClassifier   (ScikitLearn)\n",
      "GradientBoostingClassifier  (ScikitLearn)\n",
      "KNNClassifier               (NearestNeighbors)\n",
      "KNeighborsClassifier        (ScikitLearn)\n",
      "LDA                         (MultivariateStats)\n",
      "LinearBinaryClassifier      (GLM)\n",
      "LogisticCVClassifier        (ScikitLearn)\n",
      "LogisticClassifier          (MLJLinearModels)\n",
      "LogisticClassifier          (ScikitLearn)\n",
      "MultinomialClassifier       (MLJLinearModels)\n",
      "ProbabilisticSGDClassifier  (ScikitLearn)\n",
      "RandomForestClassifier      (DecisionTree)\n",
      "RandomForestClassifier      (ScikitLearn)\n",
      "SubspaceLDA                 (MultivariateStats)\n",
      "XGBoostClassifier           (XGBoost)\n"
     ]
    }
   ],
   "source": [
    "for m in models(matching(x, y))\n",
    "    if m.prediction_type == :probabilistic\n",
    "        println(rpad(m.name, 28), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos o nome de uma série de modelos do tipo probabilístico que podem ser utilizados para o nosso conjunto de dados, bem como, do nome do pacote que precisa ser instalado para usar o modelo.\n",
    "\n",
    "O que precisamos fazer agora é carregar o modelo desejado com a macro _**@load**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: A model type \"KNNClassifier\" is already loaded. \n",
      "│ No new code loaded. \n",
      "└ @ MLJModels /home/phelipe/.julia/packages/MLJModels/zduEi/src/loading.jl:43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Distances.Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = :uniform)\u001b[34m @ 1…77\u001b[39m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc = @load KNNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em alguns casos podemos ter diferentes pacotes oferecendo o mesmo modelo, como é o caso do modelo __RandomForestClassifier__ que é oferecido tanto pelo pacote __ScikitLearn__ quanto pelo pacote __DecisionTree__, neste caso podemos adicionar o nome do pacote junto do comando _**@load**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = 0,\n",
       "    n_trees = 10,\n",
       "    sampling_fraction = 0.7,\n",
       "    pdf_smoothing = 0.0)\u001b[34m @ 7…68\u001b[39m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = @load  RandomForestClassifier pkg=\"DecisionTree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook vimos um pouco sobre como utilizar os modelos, no próximo notebook veremos como utilizar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia IA 1.4.0",
   "language": "julia",
   "name": "julia-ia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
